# AI-learning

GOAL:
ç¬¬1å‘¨ï¼š
Whisper è·‘é€š
Ollama + Qwen API è°ƒé€š
TTS èƒ½æ’­è¯­éŸ³

ç¬¬2å‘¨ï¼š
åšå¯¹è¯ API
å­˜è®­ç»ƒæ•°æ®
æ„é€  JSON æ•°æ®é›†

ç¬¬3å‘¨ï¼š
è·‘ LoRA
æ¯”è¾ƒå¾®è°ƒå‰åæ•ˆæœ

ç¬¬4å‘¨ï¼š
æ•´åˆæˆè¯­éŸ³æœåŠ¡


DAY 1(26.2.9):
è¯­éŸ³ â†’ Whisper â†’ Qwen â†’ è¯­éŸ³
- ğŸ™ Record audio from microphone  
- ğŸ§  Speech-to-text using Whisper  
- ğŸ¤– Generate response using local Qwen model (Ollama)  
- ğŸ”Š Text-to-speech using Edge-TTS  
- ğŸ’» Fully local, no cloud dependency

ollama run qwen2.5:7b;
brew install ffmpeg;
pip install openai-whisper edge-tts sounddevice scipy requests

DAY 2(26.2.10):
åšå¯¹è¯ API
å­˜è®­ç»ƒæ•°æ®
æ„é€  JSON æ•°æ®é›†

è½¬ä¸ºLoRAæ ‡å‡†æ ¼å¼è„šæœ¬ï¼šconvert_dataset.py

å¾®è°ƒè„šæœ¬ï¼šlora_train.py (å®‰è£…ä¾èµ– pip install transformers datasets peft accelerate bitsandbytes
)

æµç¨‹ï¼šè¯­éŸ³ â†’ dataset.json â†’ LoRA å¾®è°ƒ â†’ å®¢æœæ¨¡å‹

ğŸ¤ â†’ Whisper â†’ Qwen â†’ ä¿å­˜ â†’ å¾®è°ƒ â†’ æ–°æ¨¡å‹ â†’ æ›´ä¸“ä¸šå›å¤

DAY 3(26.2.11):
ä¿®æ”¹ä¾èµ–ï¼Œåœ¨æœ¬åœ°å®‰è£…qwenæ¨¡å‹
 HF_ENDPOINT=https://hf-mirror.com huggingface-cli download Qwen/Qwen2.5-1.5B-Instruct --local-dir ./qwen2.5-1.5b

å¢åŠ compareè„šæœ¬ï¼ŒéªŒè¯å¾®è°ƒå‰åç»“æœ


