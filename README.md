# AI-learning

GOAL:
ç¬¬1å‘¨ï¼š
Whisper è·‘é€š
Ollama + Qwen API è°ƒé€š
TTS èƒ½æ’­è¯­éŸ³

ç¬¬2å‘¨ï¼š
åšå¯¹è¯ API
å­˜è®­ç»ƒæ•°æ®
æ„é€  JSON æ•°æ®é›†

ç¬¬3å‘¨ï¼š
è·‘ LoRA
æ¯”è¾ƒå¾®è°ƒå‰åæ•ˆæœ

ç¬¬4å‘¨ï¼š
æ•´åˆæˆè¯­éŸ³æœåŠ¡


DAY 1:
è¯­éŸ³ â†’ Whisper â†’ Qwen â†’ è¯­éŸ³
- ğŸ™ Record audio from microphone  
- ğŸ§  Speech-to-text using Whisper  
- ğŸ¤– Generate response using local Qwen model (Ollama)  
- ğŸ”Š Text-to-speech using Edge-TTS  
- ğŸ’» Fully local, no cloud dependency

ollama run qwen2.5:7b
brew install ffmpeg
pip install openai-whisper edge-tts sounddevice scipy requests
