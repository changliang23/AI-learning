
import whisper
import sounddevice as sd
import scipy.io.wavfile as wav
import requests
import asyncio
import edge_tts
import os

AUDIO_FILE = "input.wav"
REPLY_FILE = "reply.mp3"

# 1. å½•éŸ³
def record_audio(duration=5, fs=16000):
    print("ğŸ¤ å¼€å§‹å½•éŸ³...")
    audio = sd.rec(int(duration * fs), samplerate=fs, channels=1)
    sd.wait()
    wav.write(AUDIO_FILE, fs, audio)
    print("âœ… å½•éŸ³å®Œæˆ")

# 2. Whisper è½¬æ–‡å­—
def speech_to_text():
    print("ğŸ§  Whisper è½¬æ–‡å­—...")
    model = whisper.load_model("base")
    result = model.transcribe(AUDIO_FILE, language="zh")
    print("è¯†åˆ«ç»“æœ:", result["text"])
    return result["text"]

# 3. è°ƒç”¨æœ¬åœ° Ollama(Qwen)
def call_qwen(prompt):
    print("ğŸ¤– è°ƒç”¨ Qwen...")
    url = "http://localhost:11434/api/generate"
    data = {
        "model": "qwen2.5:7b",
        "prompt": prompt,
        "stream": False
    }
    r = requests.post(url, json=data)
    return r.json()["response"]

# 4. TTSï¼ˆç”Ÿæˆ MP3ï¼‰
async def text_to_speech(text):
    print("ğŸ”Š åˆæˆè¯­éŸ³...")
    communicate = edge_tts.Communicate(
        text=text,
        voice="zh-CN-XiaoxiaoNeural"
    )
    await communicate.save(REPLY_FILE)

# 5. æ’­æ”¾è¯­éŸ³ï¼ˆMacï¼‰
def play_audio():
    os.system(f"afplay {REPLY_FILE}")

# ä¸»æµç¨‹
def main():
    record_audio(5)
    user_text = speech_to_text()
    reply_text = call_qwen(user_text)
    print("AI å›å¤:", reply_text)
    asyncio.run(text_to_speech(reply_text))
    play_audio()

if __name__ == "__main__":
    main()
